# Universal Testing Patterns

*Applies to ALL projects - comprehensive testing strategies for reliable software*

## ğŸ§ª Testing Pyramid

A balanced approach to testing that prioritizes fast, reliable tests:

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   E2E Tests â”‚  â† 10% - Critical user flows
                    â”‚   (Selenium,â”‚     (slow, fragile)
                    â”‚   Playwrightâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚  Integration Tests  â”‚  â† 20% - Service interactions
               â”‚ (API endpoints, DB) â”‚     (medium speed)
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚      Unit Tests              â”‚  â† 70% - Business logic
          â”‚   (Functions, Classes)       â”‚     (fast, reliable)
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Testing Standards

### Coverage Requirements
- **Unit tests**: 80%+ coverage for business logic
- **Integration tests**: 60%+ coverage for API boundaries
- **E2E tests**: 90%+ coverage for critical user journeys
- **Total coverage**: 75%+ across all test types

### Test Speed Requirements
- **Unit tests**: < 1 second each
- **Integration tests**: < 5 seconds each
- **E2E tests**: < 30 seconds each
- **Full test suite**: < 5 minutes total

## ğŸ—ï¸ Test Organization

### Directory Structure
```
tests/
â”œâ”€â”€ conftest.py                    # Shared fixtures and configuration
â”œâ”€â”€ unit/                          # Unit tests (fast, isolated)
â”‚   â”œâ”€â”€ test_models/
â”‚   â”‚   â”œâ”€â”€ test_user.py
â”‚   â”‚   â””â”€â”€ test_item.py
â”‚   â”œâ”€â”€ test_services/
â”‚   â”‚   â”œâ”€â”€ test_pricing_service.py
â”‚   â”‚   â””â”€â”€ test_item_service.py
â”‚   â”œâ”€â”€ test_utils/
â”‚   â”‚   â”œâ”€â”€ test_calculations.py
â”‚   â”‚   â””â”€â”€ test_validators.py
â”‚   â””â”€â”€ test_clients/
â”‚       â”œâ”€â”€ test_firecrawl_client.py
â”‚       â””â”€â”€ test_external_api_client.py
â”œâ”€â”€ integration/                   # Integration tests (medium speed)
â”‚   â”œâ”€â”€ test_api/
â”‚   â”‚   â”œâ”€â”€ test_items_api.py
â”‚   â”‚   â”œâ”€â”€ test_pricing_api.py
â”‚   â”‚   â””â”€â”€ conftest.py           # API test fixtures
â”‚   â”œâ”€â”€ test_database/
â”‚   â”‚   â”œâ”€â”€ test_item_repository.py
â”‚   â”‚   â””â”€â”€ conftest.py           # Database test setup
â”‚   â””â”€â”€ test_external_services/
â”‚       â””â”€â”€ test_firecrawl_integration.py
â”œâ”€â”€ e2e/                          # End-to-end tests (slow, critical)
â”‚   â”œâ”€â”€ test_user_journeys/
â”‚   â”‚   â”œâ”€â”€ test_purchase_flow.py
â”‚   â”‚   â””â”€â”€ test_search_and_filter.py
â”‚   â”œâ”€â”€ test_critical_paths/
â”‚   â”‚   â”œâ”€â”€ test_price_calculation_e2e.py
â”‚   â”‚   â””â”€â”€ test_data_sync_e2e.py
â”‚   â””â”€â”€ conftest.py               # E2E test environment
â”œâ”€â”€ fixtures/                     # Reusable test data
â”‚   â”œâ”€â”€ sample_items.json
â”‚   â”œâ”€â”€ mock_responses/
â”‚   â””â”€â”€ test_databases/
â””â”€â”€ helpers/                      # Test utilities
    â”œâ”€â”€ assertions.py
    â”œâ”€â”€ fixtures.py
    â””â”€â”€ mock_helpers.py
```

## ğŸ§ª Unit Testing

### Test Structure (Arrange-Act-Assert)
```python
def test_calculate_bulk_discount():
    """Test that bulk discounts are applied correctly."""
    # Arrange - Set up test data
    item = Item(price=100.0, source="amazon")
    pricing_service = PricingService()
    quantity = 25

    # Act - Execute the function being tested
    total = pricing_service.calculate_item_total(item, quantity)

    # Assert - Verify the result
    expected_total = 2250.0  # 25 * 100 * 0.9 (10% bulk discount)
    assert total == expected_total
    assert item.discount_applied == 0.1
```

### Test Data Management
```python
# âœ… GOOD - Using factories for test data
from factory import Factory, LazyFunction
import random

class ItemFactory(Factory):
    class Meta:
        model = Item

    id = LazyFunction(lambda: str(uuid.uuid4()))
    name = "Test Item"
    price = 100.0
    source = "amazon"
    category = "electronics"

def test_pricing_with_various_sources():
    """Test pricing calculation with different item sources."""
    items = ItemFactory.create_batch(5, source="amazon")
    items += ItemFactory.create_batch(3, source="ebay")
    items += ItemFactory.create_batch(2, source="walmart")

    service = PricingService()
    total = service.calculate_cart_total(items)

    assert total > 0
    assert all(item.discount_applied >= 0.0 for item in items)

# âŒ BAD - Hardcoded test data
def test_pricing_with_hardcoded_data():
    item1 = Item(id="1", name="Item 1", price=100.0, source="amazon")
    item2 = Item(id="2", name="Item 2", price=50.0, source="ebay")
    # This becomes hard to maintain and extend
```

### Mocking and Patching
```python
# âœ… GOOD - Strategic mocking
def test_pricing_with_external_discount_service():
    """Test pricing that depends on external discount service."""
    # Mock the external service call
    with patch('services.PricingService.get_external_discount') as mock_discount:
        mock_discount.return_value = 0.15  # 15% external discount

        service = PricingService()
        item = ItemFactory(price=100.0, source="external")
        total = service.calculate_item_total(item, quantity=10)

        # Verify the external service was called
        mock_discount.assert_called_once_with("external", 10)
        assert total == 850.0  # 10 * 100 * 0.85
```

## ğŸ”— Integration Testing

### Database Integration Tests
```python
# conftest.py for database tests
import pytest
import asyncio
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker

@pytest.fixture(scope="session")
async def test_db():
    """Create isolated test database."""
    engine = create_async_engine("postgresql+asyncpg://test:test@localhost/test_db")
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)

    SessionLocal = sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)

    async with SessionLocal() as session:
        yield session

    await engine.dispose()

@pytest.fixture
async def item_repository(test_db):
    """Repository instance for testing."""
    return ItemRepository(test_db)

# test_file.py
@pytest.mark.asyncio
async def test_item_repository_create_and_retrieve():
    """Test CRUD operations through repository."""
    repository = item_repository
    test_item = ItemFactory()

    # Create
    created = await repository.create(test_item)
    assert created.id == test_item.id

    # Read
    retrieved = await repository.get_by_id(test_item.id)
    assert retrieved.name == test_item.name
    assert retrieved.price == test_item.price

    # Update
    retrieved.price = 200.0
    updated = await repository.update(retrieved)
    assert updated.price == 200.0

    # Delete
    await repository.delete(test_item.id)
    assert await repository.get_by_id(test_item.id) is None
```

### API Integration Tests
```python
# conftest.py for API tests
from fastapi.testclient import TestClient
from main import create_app

@pytest.fixture
def app():
    return create_app()

@pytest.fixture
def client(app):
    return TestClient(app)

# test_file.py
def test_create_item_api(client):
    """Test creating an item through API endpoint."""
    item_data = {
        "name": "Test Item",
        "price": 100.0,
        "source": "amazon"
    }

    response = client.post("/api/v1/items", json=item_data)

    assert response.status_code == 201
    data = response.json()
    assert data["name"] == item_data["name"]
    assert data["price"] == item_data["price"]
    assert "id" in data

def test_get_item_pricing_api(client):
    """Test pricing calculation endpoint."""
    # First create an item
    item = ItemFactory()
    client.post("/api/v1/items", json={
        "name": item.name,
        "price": item.price,
        "source": item.source
    })

    # Then test pricing endpoint
    response = client.get(f"/api/v1/items/{item.id}/pricing?quantity=20")

    assert response.status_code == 200
    data = response.json()
    assert "total_price" in data
    assert "discount_applied" in data
    assert data["total_price"] > 0
```

## ğŸ­ End-to-End Testing

### Critical User Journeys
```python
def test_complete_purchase_workflow():
    """Test the complete user purchase workflow."""
    with Playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()

        try:
            # Navigate to application
            page.goto("http://localhost:8000")

            # Search for items
            page.fill('[data-testid="search-input"]', "pokemon cards")
            page.click('[data-testid="search-button"]')

            # Add items to cart
            page.wait_for_selector('[data-testid="search-results"]')
            page.click('[data-testid="add-to-cart-1"]')
            page.click('[data-testid="add-to-cart-2"]')

            # View cart and checkout
            page.click('[data-testid="view-cart"]')
            page.click('[data-testid="checkout-button"]')

            # Verify total price calculation
            total_text = page.text_content('[data-testid="cart-total"]')
            assert "180.00" in total_text  # Expected total with discounts

            # Complete purchase
            page.fill('[data-testid="shipping-address"]', "123 Test St")
            page.click('[data-testid="place-order"]')

            # Verify order confirmation
            page.wait_for_selector('[data-testid="order-confirmation"]')
            confirmation_text = page.text_content('[data-testid="order-confirmation"]')
            assert "Order confirmed" in confirmation_text

        finally:
            browser.close()
```

### API Contract Testing
```python
def test_api_contract_adherence():
    """Test that API responses conform to OpenAPI schema."""
    client = TestClient(app)

    # Test required fields
    response = client.post("/api/v1/items", json={
        "name": "Test",
        "price": 100.0,
        "source": "amazon"
    })

    assert response.status_code == 201
    data = response.json()

    # Validate response structure
    assert "id" in data
    assert "name" in data
    assert "price" in data
    assert "source" in data
    assert "created_at" in data

    # Test validation errors
    invalid_response = client.post("/api/v1/items", json={
        "name": "",  # Invalid - empty name
        "price": -10.0,  # Invalid - negative price
        "source": "invalid_source"  # Invalid source
    })

    assert invalid_response.status_code == 422
    errors = invalid_response.json()["detail"]
    assert any("name" in error["loc"] and "ensure this value" in error["msg"] for error in errors)
    assert any("price" in error["loc"] and "greater than" in error["msg"] for error in errors)
```

## ğŸ”§ Test Fixtures and Factories

### Custom Fixtures
```python
# conftest.py
import pytest
from unittest.mock import Mock, patch

@pytest.fixture
def mock_pricing_service():
    """Mock pricing service for testing."""
    service = Mock()
    service.calculate_item_total.return_value = 100.0
    service.calculate_cart_total.return_value = 500.0
    return service

@pytest.fixture
def sample_user():
    """Create a test user."""
    return UserFactory(email="test@example.com", status="active")

@pytest.fixture(autouse=True)
def reset_database():
    """Reset database state before each test."""
    # This runs before each test
    yield
    # This runs after each test
    cleanup_test_data()

# fixtures/fixtures.py
class TestDataFactory:
    @staticmethod
    def create_test_items(count=1, **overrides):
        """Create multiple test items with overrides."""
        items = []
        for i in range(count):
            item = ItemFactory(
                name=f"Test Item {i}",
                price=100.0 + i,
                source="test_source",
                **overrides
            )
            items.append(item)
        return items

    @staticmethod
    def create_discount_set(item_type="bulk", percentage=10.0, min_quantity=10):
        """Create a set of related discounts."""
        return [
            Discount(type=item_type, percentage=percentage, min_quantity=min_quantity),
            Discount(type=item_type, percentage=percentage * 1.5, min_quantity=min_quantity * 2),
        ]
```

## ğŸ“Š Test Performance and Reliability

### Parallel Test Execution
```bash
# pytest.ini
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts =
    -v
    --tb=short
    --strict-markers
    --disable-warnings
    -n auto  # Run tests in parallel
    --cov=src
    --cov-report=html
    --cov-report=term
    --cov-fail-under=75
```

### Test Data Isolation
```python
# âœ… GOOD - Test isolation
@pytest.mark.asyncio
async def test_concurrent_database_operations():
    """Test that concurrent operations don't interfere."""
    # Use unique test data
    test_id = str(uuid.uuid4())
    item = ItemFactory(id=test_id)

    # Multiple operations on same data
    tasks = [
        repository.get_by_id(test_id),
        repository.update(item),
        repository.delete(test_id),
    ]

    results = await asyncio.gather(*tasks, return_exceptions=True)

    # All operations should complete successfully
    assert all(isinstance(result, (Item, type(None), NoneType)) for result in results)

# âŒ BAD - Shared test data
def test_with_shared_state():
    # This test modifies global state that affects other tests
    global CURRENT_USER
    CURRENT_USER = UserFactory()
    # ... test code that depends on global state
```

### Flaky Test Prevention
```python
# âœ… GOOD - Stable, deterministic tests
def test_timeout_handling():
    """Test timeout handling with deterministic timeouts."""
    with patch('time.sleep') as mock_sleep:
        service = APIService(timeout=1.0)

        # Mock the API call to timeout
        with patch.object(service, '_make_request') as mock_request:
            mock_request.side_effect = TimeoutError("Request timed out")

            result = service.get_data("test")

            # Should retry and eventually fail
            assert result is None
            assert mock_request.call_count >= 2  # At least 2 attempts

# âŒ BAD - Time-dependent tests
def test_with_time.sleep():
    time.sleep(2)  # This makes tests slow and brittle
    result = some_function()
    assert result == expected  # This might fail due to timing
```

## ğŸš¨ Testing Anti-Patterns

### What NOT to Do
```python
# âŒ BAD - Testing implementation details
def test_internal_calculation():
    service = PricingService()
    result = service._apply_discount(100.0, 0.1)  # Testing private method
    assert result == 90.0

# âœ… GOOD - Testing public behavior
def test_discount_application():
    service = PricingService()
    result = service.calculate_item_total(
        Item(price=100.0, source="amazon"),
        quantity=10
    )
    assert result == 900.0  # Testing the behavior, not implementation

# âŒ BAD - Complex test setup
def test_complex_workflow():
    # 50+ lines of setup code
    user = setup_user()
    item = setup_item()
    order = setup_order(user, item)
    payment = setup_payment(order)
    # ... 20 more lines of setup
    # Then 2 lines of actual test
    assert payment.status == "completed"

# âœ… GOOD - Focused, simple tests
def test_order_completion():
    order = OrderFactory(status="pending")
    payment = PaymentFactory(order=order, status="processing")

    payment.complete()

    assert payment.status == "completed"
    assert order.status == "completed"
```

## ğŸ“ˆ Continuous Testing

### Pre-commit Testing
```yaml
# .pre-commit-config.yaml
repos:
  - repo: local
    hooks:
      - id: pytest-unit
        name: Run unit tests
        entry: pytest tests/unit/ -x --tb=short
        language: system
        pass_filenames: false
        always_run: true

      - id: lint-and-typecheck
        name: Lint and type check
        entry: bash -c 'black --check . && isort --check-only . && mypy src/'
        language: system
        pass_filenames: false
        always_run: true
```

### CI/CD Testing Pipeline
```yaml
# .github/workflows/test.yml
name: Test Suite
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.9, 3.10, 3.11]

    steps:
    - uses: actions/checkout@v3
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v3
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"
        pip install pytest-xdist

    - name: Run unit tests
      run: pytest tests/unit/ -n auto --cov=src --cov-report=xml

    - name: Run integration tests
      run: pytest tests/integration/ -n 2

    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
```

---

**Remember**: Tests are not just for catching bugs - they're documentation of how your code should behave, and a safety net for refactoring. Invest in good tests, and they'll pay for themselves many times over.
